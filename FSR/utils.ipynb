{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, math, os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Get frames from video with interval(gapFrame)\n",
    "def getFrame(videoPath, savePath, gapFrame=1):\n",
    "# this code is original from https://blog.csdn.net/u010555688/article/details/79182362\n",
    "    cap = cv2.VideoCapture(videoPath)\n",
    "    numFrame = 0\n",
    "    while True:\n",
    "        if cap.grab():\n",
    "            flag, frame = cap.retrieve()\n",
    "            if not flag:\n",
    "                continue\n",
    "            else:\n",
    "                # frame = np.rot90(frame)\n",
    "                #cv2.imshow('video', frame)\n",
    "                numFrame += 1\n",
    "                #print(numFrame)\n",
    "                if (numFrame%gapFrame==0):\n",
    "                    newPath = savePath + 'Frame{:04d}.png'.format(numFrame)\n",
    "                    cv2.imencode('.png', frame)[1].tofile(newPath)\n",
    "        else:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get LR pics from HR pics by 1/blurryTimes with mode \"select\"\n",
    "def blurryList(imgFolder, svFolder, blurryTimes=4):#, mode=\"select\"\n",
    "    img_list = os.listdir(imgFolder)\n",
    "    for imgName in img_list:\n",
    "        imgPath = os.path.join(imgFolder,imgName)\n",
    "        # blurry(imgPath,svFolder,blurryTimes,mode)\n",
    "        img = cv2.imread(imgPath, cv2.IMREAD_COLOR)\n",
    "        w,h,d = img.shape\n",
    "        img = cv2.resize(img, (h//blurryTimes, w//blurryTimes),interpolation=cv2.INTER_NEAREST)\n",
    "        svpath = os.path.join(svFolder,imgName)\n",
    "        cv2.imwrite(svpath, img)\n",
    "\n",
    "# blurryList(\"./data/train_data/\",\"./data/train_data4x/\",4)#,\"select\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Get all images from specified dir, return [None,?,?,3]\n",
    "def load_images(toreadPath,split=4):\n",
    "    imgList = []\n",
    "    file_list = os.listdir(toreadPath)\n",
    "    file_list.sort(key=lambda x:int(x[5:-split]))#倒着数第四位'.'为分界线，按照‘.’左边的数字从小到大排序\n",
    "    # print(file_list)\n",
    "    for imgName in file_list:\n",
    "        imgPath = os.path.join(toreadPath,imgName)\n",
    "        img = Image.open(imgPath)\n",
    "        img_arr = np.array(img)\n",
    "        imgList.append(img_arr)\n",
    "    return np.array(imgList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BiCubic Interpolation\n",
    "def BiCubicList(imgdata,k):\n",
    "    num,a,b,c = imgdata.shape\n",
    "    bigImgs = np.zeros((num,k*a,k*b,c))\n",
    "    for i in range(num):\n",
    "        # use the implementation above\n",
    "        # bigImgs.append(BiCubic(imgdata[i,...],k))\n",
    "        # For efficiency, we use Pillow.Image.BICUBIC() method\n",
    "        rgb = Image.fromarray(np.uint8(imgdata[i,...]),\"RGB\")\n",
    "        rgb = rgb.resize((b*k,a*k), Image.BICUBIC)\n",
    "        bigImgs[i,...] = np.array(rgb)\n",
    "    return bigImgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Get all images from specified dir, return [None,?,?,3]\n",
    "def load_images_bybicubic(toreadPath,k=2,split=4):\n",
    "    imgList = []\n",
    "    file_list = os.listdir(toreadPath)\n",
    "    file_list.sort(key=lambda x:int(x[:-split]))#倒着数第四位'.'为分界线，按照‘.’左边的数字从小到大排序\n",
    "    # print(file_list)\n",
    "    for imgName in file_list:\n",
    "        imgPath = os.path.join(toreadPath,imgName)\n",
    "        img = Image.open(imgPath)\n",
    "        img_arr = np.array(img)\n",
    "        a,b,c = img_arr.shape\n",
    "        rgb = Image.fromarray(np.uint8(img_arr),\"RGB\")\n",
    "        rgb = rgb.resize((b*k,a*k), Image.BICUBIC)\n",
    "        img_arr = np.array(rgb)\n",
    "        imgList.append(img_arr)\n",
    "    return np.float32(np.array(imgList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadimgs_from_paths(x_paths,y_paths):\n",
    "    xList=[]\n",
    "    for x_path in x_paths:\n",
    "        img = Image.open(x_path)\n",
    "        img_arr = np.array(img)\n",
    "        xList.append(img_arr)\n",
    "    yList=[]\n",
    "    for y_path in y_paths:\n",
    "        img = Image.open(y_path)\n",
    "        img_arr = np.array(img)\n",
    "        yList.append(img_arr)\n",
    "    return np.array(xList),np.array(yList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def images_to_video(imgpath,svpath,videoname=\"demo\",fps=60):\n",
    "    img_array = []\n",
    "    images_list = os.listdir(imgpath)\n",
    "    images_list.sort(key=lambda x:int(x[5:-4]))\n",
    "    for i in images_list:\n",
    "        filename = os.path.join(imgpath,i)\n",
    "        print(filename)\n",
    "        img = cv2.imread(filename)\n",
    "        if img is None:\n",
    "            print(filename + \" is error!\")\n",
    "            continue\n",
    "        img_array.append(img)\n",
    "\n",
    "    out = cv2.VideoWriter(os.path.join(svpath,'%s.avi'%videoname), cv2.VideoWriter_fourcc('X','V','I','D'), fps, (img.shape[1],img.shape[0]))\n",
    " \n",
    "    for i in range(len(img_array)):\n",
    "        out.write(img_array[i])\n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FSR(tf.keras.models.Model):\n",
    "    def __init__(self,upscale):\n",
    "        # 调用父类__init__()方法\n",
    "        super(FSR, self).__init__()\n",
    "        self.conv2d_1 = tf.keras.layers.Conv2D(48, 3, strides=1, padding='same', activation=None, name=\"linear_conv1\")\n",
    "        self.conv2d_2 = tf.keras.layers.Conv2D(48, 5, strides=1, padding='same', activation='tanh', name=\"nonlinear_conv1\")\n",
    "        self.conv2d_3 = tf.keras.layers.Conv2D(48, 3, strides=1, padding='same', activation='tanh', name=\"nonlinear_conv2\")\n",
    "        self.conv2d_4 = tf.keras.layers.Conv2D(48, 3, strides=1, padding='same', activation='tanh', name=\"nonlinear_conv3\")\n",
    "        self.conv2d_5 = tf.keras.layers.Conv2D(3*upscale*upscale, 3, strides=1, padding='same', activation=None, name=\"conv\")\n",
    "        # self.conv2d_6 = tf.keras.layers.Conv2D(3, 3, strides=1, padding='same', activation='tanh', name=\"conv_last\")\n",
    "        self.r = upscale\n",
    "        #print(\"Model inited.\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        linear_conv = self.conv2d_1(inputs)\n",
    "        nonlinear_conv = self.conv2d_2(inputs)\n",
    "        nonlinear_conv = self.conv2d_3(nonlinear_conv)\n",
    "        nonlinear_conv = self.conv2d_4(nonlinear_conv)\n",
    "        fea = tf.concat([linear_conv,nonlinear_conv],axis=3)\n",
    "        fea = self.conv2d_5(fea)\n",
    "        xc = []\n",
    "        for c in range(3):\n",
    "            t = fea[:,:,:,c*self.r*self.r:c*self.r*self.r+self.r*self.r] # [B,H,W,R*R]\n",
    "            t = tf.compat.v1.depth_to_space(t, self.r) # [B,H*R,W*R,1]\n",
    "            xc += [t]\n",
    "        x = tf.concat(xc, axis=3)   # [B,H*R,W*R,3]\n",
    "        # x = self.conv2d_6(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def con_img2v(path1,path2,svpath,axis=1,videoname=\"demo\",fps=60):\n",
    "    img_array = []\n",
    "    img_list1 = os.listdir(path1)\n",
    "    img_list1.sort(key=lambda x:int(x[5:-4]))\n",
    "    img_list2 = os.listdir(path2)\n",
    "    img_list2.sort(key=lambda x:int(x[5:-4]))\n",
    "    num = min(len(img_list1),len(img_list2))\n",
    "    for i in range(num):\n",
    "        if i % 20 == 0:\n",
    "            print(\"processing: %.2f%%\" % (100*i/num))\n",
    "        file1 = os.path.join(path1,img_list1[i])\n",
    "        img1 = cv2.imread(file1)\n",
    "        file2 = os.path.join(path2,img_list2[i])\n",
    "        img2 = cv2.imread(file2)\n",
    "        if (img1 is None) or (img2 is None):\n",
    "            print(file1, file2 + \" is error!\")\n",
    "            continue\n",
    "        img = np.append(img1,img2,axis=axis)\n",
    "        img_array.append(img)\n",
    "\n",
    "    out = cv2.VideoWriter(os.path.join(svpath,'%s.mp4'%videoname), cv2.VideoWriter_fourcc('X','V','I','D'), fps, (img.shape[1],img.shape[0]))\n",
    " \n",
    "    for i in range(len(img_array)):\n",
    "        out.write(img_array[i])\n",
    "    out.release()\n",
    "    \n",
    "# con_img2v(\"temp_INTER_LINEAR\",\"temp_sr\",\"./\",1,\"concat\",20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
