# DUF

# ä»‹ç»

è¿™æ˜¯å¯¹è®ºæ–‡ã€Š[Deep Video Super-Resolution Network Using Dynamic Upsampling Filters Without Explicit Motion Compensation](https://openaccess.thecvf.com/content_cvpr_2018/papers/Jo_Deep_Video_Super-Resolution_CVPR_2018_paper.pdf)ã€‹çš„å¤ç°ï¼Œè®ºæ–‡ä¸­æå‡ºçš„ç½‘ç»œè¢«ç§°ä¸º`DUF`ï¼Œä»£ç ä½¿ç”¨TensorFlowå®ç°ã€‚åŸæ–‡çš„ä»£ç åœ°å€å¦‚ä¸‹ï¼š[https://github.com/yhjo09/VSR-DUF](https://github.com/yhjo09/VSR-DUF)ã€‚

[è®ºæ–‡æœ¬åœ°ä¸‹è½½](./DUF/Jo_Deep_Video_Super-Resolution_CVPR_2018_paper.pdf)

ä¸€ç§è€¿ç›´çš„è§†é¢‘è¶…åˆ†æ–¹æ³•æ˜¯é€å¸§è¶…åˆ†ï¼Œä½†æ˜¯è¿™æ ·åšä¼šå¤±å»å¸§ä¹‹é—´çš„æ—¶åºå…³ç³»ï¼Œå¯¼è‡´ç”»é¢ä¸è¿è´¯ã€‚

> A straightforward way to perform VSR is to run SISRframe by frame. However, since the SISR methods do notconsider the temporal relationship between frames, there isa high possibility that consecutive frames are not connectednaturally, resulting in the flickering artifact.

æ‰€æœ‰åŸºäºæ·±åº¦å­¦ä¹ çš„VSRæ–¹æ³•éƒ½æœ‰ç›¸ä¼¼çš„æ­¥éª¤ï¼Œç”±ä¸¤æ­¥ç»„æˆï¼š**ä¸€ä¸ªè¿åŠ¨ä¼°è®¡å’Œè¡¥å¿æ­¥éª¤**å’Œ**ä¸€ä¸ªä¸Šé‡‡æ ·æ­¥éª¤**ã€‚

> All deep learning based VSR methods follow similar steps and are composed of two steps: a motion estimation and compensation proce-dure followed by an upsampling process [16,22,1,24,34].

è¿™ç§æ€è·¯ä¼šæ¥å¸¦æ¥ä¸¤ä¸ªé—®é¢˜ï¼Œç¬¬ä¸€æ˜¯å¯¹äºè¿åŠ¨è¡¥å¿çš„é«˜åº¦ä¾èµ–æ€§ï¼Œç¬¬äºŒæ˜¯å¤šå¸§è¡¥å¿åçš„LRå›¾åƒå¯èƒ½ä¼šä½¿æœ€åçš„ç»“æœæ¨¡ç³Šã€‚

> One problem with this two-step approach is that the resultsrely heavily on the accurate motion estimation.  Another potential problem with this type of approach is that the HRoutput frame is produced by mixing the values from multi-ple motion compensated input LR frames through a convo-lutional neural networks (CNN), which can lead to a blurryoutput HR frame.

åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„ç«¯åˆ°ç«¯çš„æ·±åº¦ç¥ç»ç½‘ç»œï¼Œå®ƒä¸ä»¥å¾€çš„æ–¹æ³•æœ‰æœ¬è´¨çš„ä¸åŒã€‚ä¸éœ€è¦æ˜¾å¼åœ°è®¡ç®—å’Œè¡¥å¿è¾“å…¥å¸§ä¹‹é—´çš„è¿åŠ¨ï¼Œè€Œæ˜¯éšå¼åœ°åˆ©ç”¨è¿åŠ¨ä¿¡æ¯ç”ŸæˆåŠ¨æ€ä¸Šé‡‡æ ·æ»¤æ³¢å™¨ã€‚åˆ©ç”¨ç”Ÿæˆçš„ä¸Šé‡‡æ ·æ»¤æ³¢å™¨ï¼Œé€šè¿‡å¯¹è¾“å…¥ä¸­å¿ƒå¸§è¿›è¡Œå±€éƒ¨æ»¤æ³¢ï¼Œç›´æ¥æ„é€ HRå¸§ã€‚ç”±äºæˆ‘ä»¬ä¸ä¾èµ–äºè¿åŠ¨çš„æ˜¾å¼è®¡ç®—ï¼Œä¹Ÿä¸ç›´æ¥ç»„åˆæ¥è‡ªå¤šä¸ªå¸§çš„å€¼ï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥ç”Ÿæˆæ›´æ¸…æ™°å’Œä¸€è‡´çš„HRè§†é¢‘ã€‚

> In this paper, we propose a novel end-to-end deep neural network that is fundamentally different from the previous methods. Instead of explicitly computing and compensating for motion between input frames, the motion information is implicitly utilized to generate dynamic upsampling filters. With the generated upsampling filters, the HR frame is directly constructed by local filtering to the input center frame (Fig.2). As we do not rely on explicit computation of motions and do not directly combine values from multiple frames, we can generate much sharper and temporally consistent HR videos.



# ç½‘ç»œæ¶æ„

## åŠ¨æ€ä¸Šé‡‡æ ·æ»¤æ³¢å™¨

æ–‡ä¸­ä½¿ç”¨äº†`DFNï¼ˆdynamic filter networkï¼‰`ï¼Œæ–‡ç« é“¾æ¥ï¼š[Dynamic Filter Networks](https://papers.nips.cc/paper/2016/file/8bf1211fd4b7b94528899de0a43b9fb3-Paper.pdf)ã€‚DFNå¯ä»¥åˆ†ä¸ºä¸¤ç§ç±»å‹ï¼Œæœ¬æ–‡ä¸­ä½¿ç”¨çš„æ˜¯bç±»å‹ï¼Œlocal filteringï¼Œå³è¾“å…¥å›¾åƒæ¯ä¸€ä¸ªåƒç´ ç‚¹éƒ½å¯¹åº”ä¸€ä¸ªä¸åŒçš„filterã€‚

![DFN](./DUF/DFN.png)

é¦–å…ˆ`N=3`ï¼Œè¾“å…¥æ˜¯é‚»è¿‘7å¸§çš„å›¾åƒã€‚DFNçš„è¾“å‡ºæ˜¯`r^2HW`ä¸ªæ»¤æ³¢å™¨`F_t`ï¼Œæ¯ä¸ªæ»¤æ³¢å™¨çš„å°ºå¯¸æ˜¯`5x5`ï¼Œç»“æ„å¦‚ä¸‹å›¾æ‰€ç¤ºã€‚æ»¤æ³¢å™¨çš„å‘½åå¦‚ä¸‹ï¼š
$$
F_t^{y,x,v,u}
$$
å…¶ä¸­ï¼Œï¼ˆxï¼Œyï¼‰å¯¹åº”LRå›¾ä¸­çš„åæ ‡ï¼Œï¼ˆuï¼Œvï¼‰å¯¹åº”HRå›¾å¯¹åº”åŒºåŸŸä¸­ä¸åŒç‚¹çš„åæ ‡ã€‚ä¸‹å›¾ä¸­ï¼ŒDFNç”Ÿæˆäº†16ä¸ªåŠ¨æ€æ»¤æ³¢æ ¸ï¼Œæ¯ä¸ªæ»¤æ³¢æ ¸ä¸LRå›¾åƒå¯¹åº”åƒç´ åŒºåŸŸä½œä¹˜å¾—åˆ°HRåŒºåŸŸå†…å¯¹åº”ç‚¹çš„åæ ‡ã€‚

æ¯”å¦‚ï¼ŒLRçš„shapeä¸ºï¼ˆ6ï¼Œ6ï¼Œ1ï¼‰ï¼Œéœ€è¦æ”¾å¤§4å€ï¼Œåˆ™DFNç”Ÿæˆ16ï¼ˆ4^2ï¼‰ä¸ªæ»¤æ³¢æ ¸ï¼ŒHRçš„shapeä¸ºï¼ˆ24ï¼Œ24ï¼Œ1ï¼‰ï¼ŒåŸæ¥LRå›¾åƒä¸­ï¼ˆ3ï¼Œ3ï¼‰åæ ‡å¯¹åº”çš„æ˜¯HRå›¾åƒä¸­ï¼ˆ12ï¼š15ï¼Œ12ï¼š15ï¼‰åŒºåŸŸçš„åƒç´ ç‚¹ã€‚

![dynamic upsampling](./DUF/dynamic-upsampling.png)

## æ®‹å·®å­¦ä¹ 

åŠ¨æ€ä¸Šé‡‡æ ·å‡ºæ¥çš„å›¾ç‰‡ä¸¢å¤±äº†é”åº¦ä¿¡æ¯ï¼ˆsharpnessï¼‰ï¼Œé‡‡ç”¨å¤šå¸§èåˆçš„æ®‹å·®å­¦ä¹ å¯ä»¥è¡¥å……åŠ¨æ€é‡‡æ ·çš„ç»†èŠ‚ã€‚

## ç½‘ç»œè®¾è®¡

æœ¬æ–‡æå‡ºäº†ä¸€ç§æ— éœ€ç‰¹å®šçš„è¿åŠ¨è¡¥å¿çš„åŠ¨æ€ä¸Šé‡‡æ ·è§†é¢‘è¶…åˆ†ç½‘ç»œã€‚ç½‘ç»œä¸»è¦ç”±**åŠ¨æ€ä¸Šé‡‡æ ·æ»¤æ³¢å™¨ç”Ÿæˆç½‘ç»œ**å’Œ**æ®‹å·®ç½‘ç»œ**ç»„æˆï¼Œå‰è€…æ ¹æ®é‚»è¿‘`2N+1`å¸§æ¥è·å¾—åŠ¨æ€æ»¤æ³¢å™¨ï¼Œå¯¹è¾“å…¥å¸§è¿›è¡Œæ»¤æ³¢å¾—åˆ°**åŠ¨æ€æ»¤æ³¢å™¨ä¸Šé‡‡æ ·è¾“å‡º**ï¼ˆshapeä¸ºHRï¼‰ï¼Œåè€…è¾“å‡ºæ®‹å·®å›¾åƒã€‚ä¸¤ç§ç»“æœç›¸åŠ å¾—åˆ°æœ€åçš„`Output`ç»“æœã€‚

![net-stru](./DUF/net-stru.png)

## æŸå¤±å‡½æ•°

[Huber loss](https://blog.csdn.net/u013841196/article/details/89923475)

![loss function](./DUF/loss.png)

`delta`æ˜¯ä¸€ä¸ªè¶…å‚æ•°ã€‚



## ç½‘ç»œåˆ†æ

è¿™æ˜¯ä¸€ä¸ª`end-to-end`ç½‘ç»œï¼Œä¸å¿…åƒ`VESPCN`é‡‡ç”¨å¤šä¸ªæŸå¤±å‡½æ•°ç›¸åŠ ã€‚



# ç»“æœ

50ä¸ªepochä¹‹åï¼Œæ¨¡å‹çš„è¡¨ç°å¦‚å›¾ã€‚

![train loss](./DUF/train-loss.png)![train acc](./DUF/train-acc.png)

å¯¹ç‹è€…è£è€€è¶…åˆ†çš„ç»“æœå·²ç»æ”¾åœ¨Bç«™å’Œè…¾è®¯è§†é¢‘ï¼Œå·¦è¾¹æ˜¯åŒçº¿æ€§æ’å€¼ç»“æœï¼Œå³è¾¹æ˜¯DUF16è¶…åˆ†ç»“æœï¼ŒDUFè¶…åˆ†ç»“æœæ¯”åŒçº¿æ€§æ’å€¼å¥½ä¸€äº›ã€‚[è§†é¢‘é“¾æ¥ğŸ”—](https://v.qq.com/x/page/t325055ophw.html)

<center><iframe src="http://player.bilibili.com/player.html?aid=973404988&bvid=BV1k44y1z7Ea&cid=348729269&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" height="600" allowfullscreen="true"> </iframe></center>

<center><iframe height="600" width="100%" src="https://v.qq.com/txp/iframe/player.html?vid=i3250vethx7" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe></center>

DUFæ•ˆæœï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼ˆæ‘˜è‡ªpaperï¼‰ã€‚

![paper-result](./DUF/results.png)



# ä½œè€…

æœ±æ–‡åº·

å¦‚æœä½ æœ‰é—®é¢˜ï¼Œæ¬¢è¿è”ç³»æˆ‘ã€‚æˆ‘çš„é‚®ç®±æ˜¯ï¼š[1119741654@qq.com](1119741654@qq.com)ï¼Œä¹æ„å›å¤ã€‚

è°¢è°¢ã€‚



# å‚è€ƒæ–‡çŒ®

- [https://www.pianshen.com/article/17201609448/](https://www.pianshen.com/article/17201609448/)
- [å­¦ä¹ ç¬”è®°ä¹‹â€”â€”åŸºäºæ·±åº¦å­¦ä¹ çš„å›¾åƒè¶…åˆ†è¾¨ç‡é‡å»º](https://blog.csdn.net/gwplovekimi/article/details/83041627?utm_medium=distribute.pc_relevant_download.none-task-blog-baidujs-8.nonecase&depth_1-utm_source=distribute.pc_relevant_download.none-task-blog-baidujs-8.nonecase#ESPCN%EF%BC%88Efficient%20Sub-Pixel%20Convolutional%20Neural%20Network%EF%BC%89)
- [è®¡ç®—æœºè§†è§‰--å…‰æµæ³•(optical flow)ç®€ä»‹](https://blog.csdn.net/qq_41368247/article/details/82562165)
- [å›å½’æŸå¤±å‡½æ•°ï¼šHuber Loss](https://blog.csdn.net/u013841196/article/details/89923475)
- [Dynamic Filter Networks](https://papers.nips.cc/paper/2016/file/8bf1211fd4b7b94528899de0a43b9fb3-Paper.pdf)
- Github: [https://github.com/yhjo09/VSR-DUF](https://github.com/yhjo09/VSR-DUF)

