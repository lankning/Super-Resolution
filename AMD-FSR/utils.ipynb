{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, math, os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Get frames from video with interval(gapFrame)\n",
    "def getFrame(videoPath, savePath, gapFrame=1):\n",
    "# this code is original from https://blog.csdn.net/u010555688/article/details/79182362\n",
    "    cap = cv2.VideoCapture(videoPath)\n",
    "    numFrame = 0\n",
    "    while True:\n",
    "        if cap.grab():\n",
    "            flag, frame = cap.retrieve()\n",
    "            if not flag:\n",
    "                continue\n",
    "            else:\n",
    "                # frame = np.rot90(frame)\n",
    "                #cv2.imshow('video', frame)\n",
    "                numFrame += 1\n",
    "                #print(numFrame)\n",
    "                if (numFrame%gapFrame==0):\n",
    "                    newPath = savePath + 'Frame{:04d}.png'.format(numFrame)\n",
    "                    cv2.imencode('.png', frame)[1].tofile(newPath)\n",
    "        else:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get LR pics from HR pics by 1/blurryTimes with mode \"select\"\n",
    "def blurryList(imgFolder, svFolder, blurryTimes=4):#, mode=\"select\"\n",
    "    img_list = os.listdir(imgFolder)\n",
    "    for imgName in img_list:\n",
    "        imgPath = os.path.join(imgFolder,imgName)\n",
    "        # blurry(imgPath,svFolder,blurryTimes,mode)\n",
    "        img = cv2.imread(imgPath, cv2.IMREAD_COLOR)\n",
    "        w,h,d = img.shape\n",
    "        img = cv2.resize(img, (h//blurryTimes, w//blurryTimes),interpolation=cv2.INTER_NEAREST)\n",
    "        svpath = os.path.join(svFolder,imgName)\n",
    "        cv2.imwrite(svpath, img)\n",
    "\n",
    "# blurryList(\"./data/train_data/\",\"./data/train_data4x/\",4)#,\"select\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Get all images from specified dir, return [None,?,?,3]\n",
    "def load_images(toreadPath,split=4):\n",
    "    imgList = []\n",
    "    file_list = os.listdir(toreadPath)\n",
    "    file_list.sort(key=lambda x:int(x[5:-split]))#倒着数第四位'.'为分界线，按照‘.’左边的数字从小到大排序\n",
    "    # print(file_list)\n",
    "    for imgName in file_list:\n",
    "        imgPath = os.path.join(toreadPath,imgName)\n",
    "        img = Image.open(imgPath)\n",
    "        img_arr = np.array(img)\n",
    "        imgList.append(img_arr)\n",
    "    return np.array(imgList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BiCubic Interpolation\n",
    "def BiCubicList(imgdata,k):\n",
    "    num,a,b,c = imgdata.shape\n",
    "    bigImgs = np.zeros((num,k*a,k*b,c))\n",
    "    for i in range(num):\n",
    "        # use the implementation above\n",
    "        # bigImgs.append(BiCubic(imgdata[i,...],k))\n",
    "        # For efficiency, we use Pillow.Image.BICUBIC() method\n",
    "        rgb = Image.fromarray(np.uint8(imgdata[i,...]),\"RGB\")\n",
    "        rgb = rgb.resize((b*k,a*k), Image.BICUBIC)\n",
    "        bigImgs[i,...] = np.array(rgb)\n",
    "    return bigImgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Get all images from specified dir, return [None,?,?,3]\n",
    "def load_images_bybicubic(toreadPath,k=2,split=4):\n",
    "    imgList = []\n",
    "    file_list = os.listdir(toreadPath)\n",
    "    file_list.sort(key=lambda x:int(x[:-split]))#倒着数第四位'.'为分界线，按照‘.’左边的数字从小到大排序\n",
    "    # print(file_list)\n",
    "    for imgName in file_list:\n",
    "        imgPath = os.path.join(toreadPath,imgName)\n",
    "        img = Image.open(imgPath)\n",
    "        img_arr = np.array(img)\n",
    "        a,b,c = img_arr.shape\n",
    "        rgb = Image.fromarray(np.uint8(img_arr),\"RGB\")\n",
    "        rgb = rgb.resize((b*k,a*k), Image.BICUBIC)\n",
    "        img_arr = np.array(rgb)\n",
    "        imgList.append(img_arr)\n",
    "    return np.float32(np.array(imgList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadimgs_from_paths(x_paths,y_paths):\n",
    "    xList=[]\n",
    "    for x_path in x_paths:\n",
    "        img = Image.open(x_path)\n",
    "        img_arr = np.array(img)\n",
    "        xList.append(img_arr)\n",
    "    yList=[]\n",
    "    for y_path in y_paths:\n",
    "        img = Image.open(y_path)\n",
    "        img_arr = np.array(img)\n",
    "        yList.append(img_arr)\n",
    "    return np.array(xList),np.array(yList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def images_to_video(imgpath,svpath,videoname=\"demo\",fps=60):\n",
    "    img_array = []\n",
    "    images_list = os.listdir(imgpath)\n",
    "    images_list.sort(key=lambda x:int(x[5:-4]))\n",
    "    for i in images_list:\n",
    "        filename = os.path.join(imgpath,i)\n",
    "        print(filename)\n",
    "        img = cv2.imread(filename)\n",
    "        if img is None:\n",
    "            print(filename + \" is error!\")\n",
    "            continue\n",
    "        img_array.append(img)\n",
    "\n",
    "    out = cv2.VideoWriter(os.path.join(svpath,'%s.avi'%videoname), cv2.VideoWriter_fourcc('X','V','I','D'), fps, (img.shape[1],img.shape[0]))\n",
    " \n",
    "    for i in range(len(img_array)):\n",
    "        out.write(img_array[i])\n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DUF_Conv(tf.keras.models.Model):\n",
    "    def __init__(self,uf):\n",
    "        # 调用父类__init__()方法\n",
    "        super(DUF_Conv, self).__init__()\n",
    "        self.conv3d_1 = tf.keras.layers.Conv3D(64, 3, strides=1, padding='valid', activation='relu', name=\"conv1\")\n",
    "        self.rconv1a = tf.keras.layers.Conv3D(64, 1, strides=(1,1,1), padding='valid', activation='relu', name=\"rconv1a\")\n",
    "        self.rconv1b = tf.keras.layers.Conv3D(32, 3, strides=1, padding='valid', activation='relu', name=\"rconv1b\")\n",
    "        self.rconv2a = tf.keras.layers.Conv3D(96, 1, strides=(1,1,1), padding='valid', activation='relu', name=\"rconv2a\")\n",
    "        self.rconv2b = tf.keras.layers.Conv3D(32, 3, strides=1, padding='valid', activation='relu', name=\"rconv2b\")\n",
    "        self.rconv3a = tf.keras.layers.Conv3D(128, 1, strides=(1,1,1), padding='valid', activation='relu', name=\"rconv3a\")\n",
    "        self.rconv3b = tf.keras.layers.Conv3D(32, 3, strides=1, padding='valid', activation='relu', name=\"rconv3b\")\n",
    "        self.rconv4a = tf.keras.layers.Conv3D(160, 1, strides=(1,1,1), padding='valid', activation='relu', name=\"rconv4a\")\n",
    "        self.rconv4b = tf.keras.layers.Conv3D(32, 3, strides=1, padding='valid', activation='relu', name=\"rconv4b\")\n",
    "        self.rconv5a = tf.keras.layers.Conv3D(192, 1, strides=(1,1,1), padding='valid', activation='relu', name=\"rconv5a\")\n",
    "        self.rconv5b = tf.keras.layers.Conv3D(32, 3, strides=1, padding='valid', activation='relu', name=\"rconv5b\")\n",
    "        self.rconv6a = tf.keras.layers.Conv3D(224, 1, strides=(1,1,1), padding='valid', activation='relu', name=\"rconv6a\")\n",
    "        self.rconv6b = tf.keras.layers.Conv3D(32, 3, strides=1, padding='valid', activation='relu', name=\"rconv6b\")\n",
    "        self.bn1a = tf.keras.layers.BatchNormalization()\n",
    "        self.bn1b = tf.keras.layers.BatchNormalization()\n",
    "        self.bn2a = tf.keras.layers.BatchNormalization()\n",
    "        self.bn2b = tf.keras.layers.BatchNormalization()\n",
    "        self.bn3a = tf.keras.layers.BatchNormalization()\n",
    "        self.bn3b = tf.keras.layers.BatchNormalization()\n",
    "        self.bn4a = tf.keras.layers.BatchNormalization()\n",
    "        self.bn4b = tf.keras.layers.BatchNormalization()\n",
    "        self.bn5a = tf.keras.layers.BatchNormalization()\n",
    "        self.bn5b = tf.keras.layers.BatchNormalization()\n",
    "        self.bn6a = tf.keras.layers.BatchNormalization()\n",
    "        self.bn6b = tf.keras.layers.BatchNormalization()\n",
    "        # ------\n",
    "        #self.fbn1 = tf.keras.layers.BatchNormalization()\n",
    "        self.conv3d_s = tf.keras.layers.Conv3D(256,3,strides=(1,1,1),padding=\"valid\", activation='relu', name=\"conv3d_s\")\n",
    "        \n",
    "        self.rconv1 = tf.keras.layers.Conv3D(256,1,strides=(1,1,1),padding=\"valid\", activation='relu', name=\"rconv1\")\n",
    "        self.rconv2 = tf.keras.layers.Conv3D(3*uf*uf,1,strides=(1,1,1),padding=\"valid\", activation='relu', name=\"rconv2\")\n",
    "        \n",
    "        self.fconv1 = tf.keras.layers.Conv3D(512,1,strides=(1,1,1),padding=\"valid\", activation='relu', name=\"fconv1\")\n",
    "        self.fconv2 = tf.keras.layers.Conv3D(1*5*5*uf*uf,1,strides=(1,1,1),padding=\"valid\", activation='relu', name=\"fconv2\")\n",
    "        \n",
    "        self.uf = uf\n",
    "        self.stp = [[0,0], [1,1], [1,1], [1,1], [0,0]]\n",
    "        self.sp = [[0,0], [0,0], [1,1], [1,1], [0,0]]\n",
    "        #print(\"Model inited.\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        #print(\"inputs: \",inputs)\n",
    "        x = self.conv3d_1(tf.pad(inputs, paddings=self.sp, mode='CONSTANT', name=\"padding\"))\n",
    "        #print(\"x:\",x)\n",
    "        \n",
    "        t = self.bn1a(x)\n",
    "        t = self.rconv1a(t)\n",
    "        t = self.bn1b(t)\n",
    "        t = self.rconv1b(tf.pad(t, paddings=self.stp, mode='CONSTANT', name=\"padding\"))\n",
    "        x = tf.concat([x, t], 4)\n",
    "        #print(\"x:\",x)\n",
    "        t = self.bn2a(x)\n",
    "        t = self.rconv2a(t)\n",
    "        t = self.bn2b(t)\n",
    "        t = self.rconv2b(tf.pad(t, paddings=self.stp, mode='CONSTANT', name=\"padding\"))\n",
    "        x = tf.concat([x, t], 4)\n",
    "        #print(\"x:\",x)\n",
    "        t = self.bn3a(x)\n",
    "        t = self.rconv3a(t)\n",
    "        t = self.bn3b(t)\n",
    "        t = self.rconv3b(tf.pad(t, paddings=self.stp, mode='CONSTANT', name=\"padding\"))\n",
    "        x = tf.concat([x, t], 4)\n",
    "        #print(\"x:\",x)\n",
    "        t = self.bn4a(x)\n",
    "        t = self.rconv4a(t)\n",
    "        t = self.bn4b(t)\n",
    "        t = self.rconv4b(tf.pad(t, paddings=self.stp, mode='CONSTANT', name=\"padding\"))\n",
    "        x = tf.concat([x, t], 4)\n",
    "        #print(\"x:\",x)\n",
    "        t = self.bn5a(x)\n",
    "        t = self.rconv5a(t)\n",
    "        t = self.bn5b(t)\n",
    "        t = self.rconv5b(tf.pad(t, paddings=self.stp, mode='CONSTANT', name=\"padding\"))\n",
    "        x = tf.concat([x, t], 4)\n",
    "        #print(\"x:\",x)\n",
    "        t = self.bn6a(x)\n",
    "        t = self.rconv6a(t)\n",
    "        t = self.bn6b(t)\n",
    "        t = self.rconv6b(tf.pad(t, paddings=self.stp, mode='CONSTANT', name=\"padding\"))\n",
    "        x = tf.concat([x, t], 4)\n",
    "        #print(\"x:\",x)\n",
    "        #x = self.fbn1(x)\n",
    "        x = self.conv3d_s(tf.pad(t, paddings=self.stp, mode='CONSTANT', name=\"padding\"))\n",
    "        x = tf.nn.relu(x)\n",
    "        #print(x)\n",
    "        \n",
    "        r = self.rconv1(x)\n",
    "        r = self.rconv2(r)\n",
    "        #print(r)\n",
    "        \n",
    "        f = self.fconv1(x)\n",
    "        f = self.fconv2(f)\n",
    "        #print(f)\n",
    "        \n",
    "        ds_f = tf.shape(f)\n",
    "        f = tf.reshape(f, [ds_f[0], ds_f[1], ds_f[2], ds_f[3], 25, self.uf*self.uf])\n",
    "        f = tf.nn.softmax(f, axis=4)\n",
    "        #print(f)\n",
    "\n",
    "        return f,r\n",
    "    \n",
    "def DynFilter3D(x, F, filter_size):\n",
    "    '''\n",
    "    3D Dynamic filtering\n",
    "    input x: (b, t, h, w)\n",
    "          F: (b, h, w, tower_depth, output_depth)\n",
    "          filter_shape (ft, fh, fw)\n",
    "    '''\n",
    "    # make tower\n",
    "    filter_localexpand_np = np.reshape(np.eye(np.prod(filter_size), np.prod(filter_size)), (filter_size[1], filter_size[2], filter_size[0], np.prod(filter_size)))\n",
    "    filter_localexpand = tf.Variable(filter_localexpand_np, trainable=False, dtype='float32',name='filter_localexpand') \n",
    "    x = tf.transpose(x, perm=[0,2,3,1])\n",
    "    x_localexpand = tf.nn.conv2d(x, filter_localexpand, [1,1,1,1], 'SAME') # b, h, w, 1*5*5\n",
    "    x_localexpand = tf.expand_dims(x_localexpand, axis=3)  # b, h, w, 1, 1*5*5\n",
    "    x = tf.matmul(x_localexpand, F) # b, h, w, 1, R*R\n",
    "    x = tf.squeeze(x, axis=3) # b, h, w, R*R\n",
    "    return x\n",
    "\n",
    "def depth_to_space_3D(x, block_size):\n",
    "    ds_x = tf.shape(x)\n",
    "    x = tf.reshape(x, [ds_x[0]*ds_x[1], ds_x[2], ds_x[3], ds_x[4]])\n",
    "    \n",
    "    y = tf.compat.v1.depth_to_space(x, block_size)\n",
    "    \n",
    "    ds_y = tf.shape(y)\n",
    "    x = tf.reshape(y, [ds_x[0], ds_x[1], ds_y[1], ds_y[2], ds_y[3]])\n",
    "    return x\n",
    "\n",
    "class DUF(tf.keras.models.Model):\n",
    "    def __init__(self,uf,T_in):\n",
    "        # 调用父类__init__()方法\n",
    "        super(DUF, self).__init__()\n",
    "        self.duf_conv = DUF_Conv(uf=uf)\n",
    "        self.T_in = T_in\n",
    "        self.uf = uf\n",
    "        #print(\"Model inited.\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        Fx, Rx = self.duf_conv(inputs)\n",
    "        #print(\"Fx: \",Fx)\n",
    "        #print(\"Rx: \",Rx)\n",
    "        x_c = []\n",
    "        for c in range(3):\n",
    "            t = DynFilter3D(inputs[:,self.T_in//2:self.T_in//2+1,:,:,c], Fx[:,0,:,:,:,:], [1,5,5]) # [B,H,W,R*R]\n",
    "            t = tf.compat.v1.depth_to_space(t, self.uf) # [B,H*R,W*R,1]\n",
    "            x_c += [t]\n",
    "        x = tf.concat(x_c, axis=3)   # [B,H*R,W*R,3]\n",
    "        x = tf.expand_dims(x, axis=1)\n",
    "        Rx = depth_to_space_3D(Rx, self.uf)   # [B,1,H*R,W*R,3]\n",
    "        x += Rx\n",
    "        x = tf.squeeze(x, axis=1)\n",
    "        #print(\"Out: \",x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def con_img2v(path1,path2,svpath,axis=1,videoname=\"demo\",fps=60):\n",
    "    img_array = []\n",
    "    img_list1 = os.listdir(path1)\n",
    "    img_list1.sort(key=lambda x:int(x[5:-4]))\n",
    "    img_list2 = os.listdir(path2)\n",
    "    img_list2.sort(key=lambda x:int(x[5:-4]))\n",
    "    num = min(len(img_list1),len(img_list2))\n",
    "    for i in range(num):\n",
    "        if i % 20 == 0:\n",
    "            print(\"processing: %.2f%%\" % (100*i/num))\n",
    "        file1 = os.path.join(path1,img_list1[i])\n",
    "        img1 = cv2.imread(file1)\n",
    "        file2 = os.path.join(path2,img_list2[i])\n",
    "        img2 = cv2.imread(file2)\n",
    "        if (img1 is None) or (img2 is None):\n",
    "            print(file1, file2 + \" is error!\")\n",
    "            continue\n",
    "        img = np.append(img1,img2,axis=axis)\n",
    "        img_array.append(img)\n",
    "\n",
    "    out = cv2.VideoWriter(os.path.join(svpath,'%s.mp4'%videoname), cv2.VideoWriter_fourcc('X','V','I','D'), fps, (img.shape[1],img.shape[0]))\n",
    " \n",
    "    for i in range(len(img_array)):\n",
    "        out.write(img_array[i])\n",
    "    out.release()\n",
    "    \n",
    "# con_img2v(\"temp_INTER_LINEAR\",\"temp_sr\",\"./\",1,\"concat\",20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
